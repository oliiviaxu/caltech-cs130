         2742964 function calls (2662192 primitive calls) in 0.559 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.560    0.560 case.py:548(_callTestMethod)
        1    0.000    0.000    0.560    0.560 test_performance.py:40(rename_stress_test)
       10    0.000    0.000    0.531    0.053 Workbook.py:239(set_cell_contents)
       38    0.000    0.000    0.515    0.014 lark.py:561(open)
       38    0.001    0.000    0.514    0.014 lark.py:267(__init__)
       10    0.001    0.000    0.399    0.040 Workbook.py:154(handle_update_tree)
       30    0.000    0.000    0.397    0.013 Workbook.py:197(evaluate_cell)
       38    0.000    0.000    0.355    0.009 load_grammar.py:1413(load_grammar)
    76/38    0.001    0.000    0.342    0.009 load_grammar.py:1239(load_grammar)
        1    0.000    0.000    0.271    0.271 testStructures.py:19(create_chain_2)
       76    0.000    0.000    0.230    0.003 load_grammar.py:964(_parse_grammar)
        1    0.000    0.000    0.229    0.229 Workbook.py:555(rename_sheet)
       38    0.001    0.000    0.219    0.006 load_grammar.py:1306(do_import)
      114    0.000    0.000    0.190    0.002 parser_frontends.py:100(parse)
       76    0.000    0.000    0.149    0.002 lalr_parser.py:40(parse)
       76    0.000    0.000    0.149    0.002 lalr_parser.py:83(parse)
       76    0.003    0.000    0.149    0.002 lalr_parser.py:91(parse_from_state)
     2128    0.011    0.000    0.120    0.000 visitors.py:282(transform)
       38    0.003    0.000    0.097    0.003 load_grammar.py:690(compile)
76010/72470    0.014    0.000    0.088    0.000 visitors.py:143(_transform_children)
    12882    0.057    0.000    0.082    0.000 lalr_parser_state.py:67(feed_token)
     9612    0.038    0.000    0.074    0.000 tree.py:133(iter_subtrees)
    38762    0.017    0.000    0.073    0.000 visitors.py:111(_call_userfunc)
       39    0.000    0.000    0.069    0.002 parser_frontends.py:48(__init__)
    29868    0.004    0.000    0.067    0.000 visitors.py:279(_transform_tree)
    12882    0.002    0.000    0.063    0.000 lexer.py:512(lex)
    12882    0.016    0.000    0.061    0.000 lexer.py:590(next_token)
       38    0.000    0.000    0.060    0.002 lark.py:481(_build_parser)
     1672    0.001    0.000    0.057    0.000 load_grammar.py:1219(_unpack_definition)
      684    0.001    0.000    0.056    0.000 visitors.py:262(transform)
       38    0.000    0.000    0.056    0.001 parser_frontends.py:246(_construct_parsing_frontend)
       38    0.000    0.000    0.056    0.001 parser_frontends.py:201(create_earley_parser)
       38    0.000    0.000    0.056    0.001 parser_frontends.py:188(create_earley_parser__dynamic)
     1672    0.003    0.000    0.055    0.000 load_grammar.py:1043(_mangle_definition_tree)
       76    0.006    0.000    0.048    0.001 load_grammar.py:868(resolve_term_references)
24358/1026    0.019    0.000    0.045    0.000 copy.py:128(deepcopy)
7030/1026    0.003    0.000    0.044    0.000 tree.py:201(__deepcopy__)
7030/1026    0.004    0.000    0.042    0.000 copy.py:201(_deepcopy_list)
       38    0.000    0.000    0.041    0.001 lark.py:637(parse)
       38    0.000    0.000    0.041    0.001 earley.py:263(parse)
       38    0.000    0.000    0.034    0.001 xearley.py:31(__init__)
       38    0.001    0.000    0.034    0.001 earley.py:32(__init__)
   108146    0.024    0.000    0.032    0.000 tree.py:142(<listcomp>)
     4104    0.001    0.000    0.032    0.000 tree.py:168(find_data)
     4104    0.001    0.000    0.031    0.000 tree.py:164(find_pred)
       38    0.000    0.000    0.028    0.001 xearley.py:39(_parse)
    19076    0.005    0.000    0.028    0.000 lexer.py:587(match)
       39    0.001    0.000    0.027    0.001 grammar_analysis.py:141(__init__)
       38    0.000    0.000    0.024    0.001 load_grammar.py:710(<listcomp>)
      438    0.005    0.000    0.024    0.000 earley.py:78(predict_and_complete)
       39    0.011    0.000    0.023    0.001 grammar_analysis.py:78(calculate_sets)
92181/70103    0.014    0.000    0.022    0.000 {built-in method builtins.getattr}
       38    0.000    0.000    0.021    0.001 parser_frontends.py:168(__init__)
      562    0.001    0.000    0.020    0.000 utils.py:132(get_regexp_width)
    19076    0.006    0.000    0.020    0.000 lexer.py:387(match)
     1026    0.008    0.000    0.020    0.000 visitors.py:297(transform)
      607    0.001    0.000    0.019    0.000 sre_parse.py:944(parse)
 1171/607    0.002    0.000    0.017    0.000 sre_parse.py:436(_parse_sub)
 1536/679    0.007    0.000    0.016    0.000 sre_parse.py:494(_parse)
   431711    0.016    0.000    0.016    0.000 {built-in method builtins.isinstance}
    35116    0.008    0.000    0.014    0.000 grammar.py:18(__eq__)
       76    0.000    0.000    0.014    0.000 load_grammar.py:921(_get_parser)
       38    0.000    0.000    0.013    0.000 load_grammar.py:1374(build)
     3154    0.001    0.000    0.013    0.000 visitors.py:503(_vargs_inline)
       38    0.001    0.000    0.013    0.000 load_grammar.py:1342(validate)
      684    0.000    0.000    0.013    0.000 load_grammar.py:674(nr_deepcopy_tree)
    20127    0.012    0.000    0.012    0.000 {method 'match' of 're.Pattern' objects}
     3154    0.001    0.000    0.012    0.000 visitors.py:481(__call__)
      950    0.002    0.000    0.012    0.000 copy.py:259(_reconstruct)
       38    0.000    0.000    0.012    0.000 earley.py:307(<listcomp>)
       38    0.000    0.000    0.012    0.000 earley_forest.py:388(transform)
       38    0.000    0.000    0.012    0.000 earley_forest.py:526(visit)
       38    0.004    0.000    0.011    0.000 earley_forest.py:274(visit)
    34048    0.010    0.000    0.011    0.000 tree.py:62(meta)
    30894    0.007    0.000    0.011    0.000 visitors.py:175(__default__)
2222/2085    0.002    0.000    0.011    0.000 utils.py:260(bfs)
        1    0.000    0.000    0.011    0.011 parser_frontends.py:157(create_lalr_parser)
        1    0.000    0.000    0.010    0.010 lalr_parser.py:18(__init__)
    14810    0.004    0.000    0.010    0.000 lexer.py:202(__new__)
   294992    0.010    0.000    0.010    0.000 {built-in method builtins.id}
    48248    0.006    0.000    0.010    0.000 grammar.py:124(__eq__)
  758/378    0.001    0.000    0.010    0.000 visitors.py:366(visit)
     3154    0.001    0.000    0.010    0.000 visitors.py:484(__get__)
      450    0.001    0.000    0.009    0.000 grammar_analysis.py:180(expand_rule)
    78783    0.007    0.000    0.009    0.000 grammar.py:25(__hash__)
    15770    0.007    0.000    0.009    0.000 parse_tree_builder.py:145(__call__)
    71326    0.009    0.000    0.009    0.000 tree.py:57(__init__)
     3154    0.001    0.000    0.008    0.000 visitors.py:474(__init__)
      798    0.000    0.000    0.008    0.000 load_grammar.py:601(literal)
2506/1784    0.001    0.000    0.008    0.000 visitors.py:346(_call_userfunc)
      798    0.001    0.000    0.008    0.000 load_grammar.py:566(_literal_to_pattern)
      684    0.000    0.000    0.008    0.000 load_grammar.py:915(_find_used_symbols)
        1    0.000    0.000    0.008    0.008 lalr_analysis.py:327(compute_lalr)
    19076    0.006    0.000    0.007    0.000 lexer.py:292(feed)
      950    0.001    0.000    0.007    0.000 copy.py:210(_deepcopy_tuple)
    14810    0.005    0.000    0.007    0.000 lexer.py:213(_future_new)
     3154    0.004    0.000    0.007    0.000 functools.py:35(update_wrapper)
       38    0.000    0.000    0.007    0.000 load_grammar.py:694(<listcomp>)
   193134    0.007    0.000    0.007    0.000 {method 'append' of 'list' objects}
94343/88824    0.005    0.000    0.007    0.000 {built-in method builtins.hash}
      950    0.000    0.000    0.006    0.000 copy.py:211(<listcomp>)
     3048    0.002    0.000    0.006    0.000 grammar_analysis.py:187(_expand_rule)
153757/151904    0.006    0.000    0.006    0.000 {built-in method builtins.len}
     9117    0.002    0.000    0.006    0.000 utils.py:330(add)
       38    0.000    0.000    0.006    0.000 load_grammar.py:693(<listcomp>)
    19608    0.004    0.000    0.006    0.000 copy.py:243(_keep_alive)
    25932    0.005    0.000    0.006    0.000 lexer.py:265(__eq__)
     8516    0.003    0.000    0.005    0.000 visitors.py:130(_call_userfunc_token)
     6064    0.003    0.000    0.005    0.000 earley_common.py:9(__init__)
 1634/912    0.001    0.000    0.004    0.000 load_grammar.py:389(expansion)
     1276    0.001    0.000    0.004    0.000 re.py:288(_compile)
     4360    0.001    0.000    0.004    0.000 earley_common.py:28(__eq__)
      798    0.001    0.000    0.004    0.000 load_grammar.py:540(eval_escaping)
      632    0.001    0.000    0.004    0.000 earley.py:135(<listcomp>)
      563    0.000    0.000    0.004    0.000 re.py:249(compile)
     1900    0.001    0.000    0.004    0.000 copy.py:227(_deepcopy_dict)
      684    0.001    0.000    0.004    0.000 load_grammar.py:917(<setcomp>)
      400    0.001    0.000    0.004    0.000 xearley.py:41(scan)
       38    0.000    0.000    0.004    0.000 lark.py:467(_prepare_callbacks)
       45    0.000    0.000    0.003    0.000 sre_compile.py:783(compile)
    65722    0.003    0.000    0.003    0.000 grammar.py:121(__hash__)
      344    0.000    0.000    0.003    0.000 visitors.py:159(transform)
        1    0.000    0.000    0.003    0.003 lalr_analysis.py:157(__init__)
    19076    0.002    0.000    0.003    0.000 lexer.py:581(scanner)
      798    0.001    0.000    0.003    0.000 ast.py:54(literal_eval)
      874    0.001    0.000    0.003    0.000 earley_forest.py:428(_visit_node_out_helper)
        1    0.000    0.000    0.003    0.003 lalr_analysis.py:166(compute_lr0_states)
8892/2508    0.002    0.000    0.003    0.000 tree.py:185(scan_values)
 1256/344    0.001    0.000    0.003    0.000 visitors.py:155(_transform_tree)
      190    0.000    0.000    0.003    0.000 load_grammar.py:405(<listcomp>)
      322    0.000    0.000    0.003    0.000 lalr_analysis.py:171(step)
     2508    0.001    0.000    0.003    0.000 load_grammar.py:384(_flatten)
    12350    0.002    0.000    0.002    0.000 parse_tree_builder.py:20(__call__)
    51605    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}
       39    0.000    0.000    0.002    0.000 parse_tree_builder.py:332(__init__)
      684    0.001    0.000    0.002    0.000 load_grammar.py:420(expansions)
     2532    0.001    0.000    0.002    0.000 utils.py:327(__contains__)
      875    0.001    0.000    0.002    0.000 parse_tree_builder.py:340(_init_builders)
     6552    0.001    0.000    0.002    0.000 sre_parse.py:255(get)
        1    0.000    0.000    0.002    0.002 parser_frontends.py:146(create_basic_lexer)
        1    0.000    0.000    0.002    0.002 lexer.py:526(__init__)
      199    0.001    0.000    0.002    0.000 utils.py:23(classify)
    40394    0.002    0.000    0.002    0.000 tree.py:170(<lambda>)
 2011/769    0.002    0.000    0.002    0.000 sre_parse.py:175(getwidth)
     1748    0.001    0.000    0.002    0.000 lexer.py:262(__deepcopy__)
     3192    0.002    0.000    0.002    0.000 tree.py:174(expand_kids_by_data)
      456    0.000    0.000    0.002    0.000 earley_forest.py:630(visit_packed_node_out)
     1596    0.001    0.000    0.002    0.000 load_grammar.py:896(<listcomp>)
     1672    0.001    0.000    0.002    0.000 load_grammar.py:1127(_define)
    10768    0.002    0.000    0.002    0.000 grammar_analysis.py:70(update_set)
      418    0.000    0.000    0.002    0.000 earley_forest.py:617(visit_symbol_node_in)
     1330    0.002    0.000    0.002    0.000 load_grammar.py:908(terminal)
     9363    0.002    0.000    0.002    0.000 sre_parse.py:234(__next)
       38    0.000    0.000    0.002    0.000 load_grammar.py:840(__call__)
      836    0.001    0.000    0.002    0.000 parse_tree_builder.py:162(maybe_create_child_filter)
      456    0.000    0.000    0.002    0.000 earley_forest.py:441(visit_packed_node_out)
      798    0.000    0.000    0.002    0.000 ast.py:33(parse)
    15799    0.002    0.000    0.002    0.000 {built-in method __new__ of type object at 0x10277eff8}
    17214    0.002    0.000    0.002    0.000 tree.py:28(__init__)
       38    0.000    0.000    0.002    0.000 pkgutil.py:599(get_data)
        1    0.001    0.001    0.002    0.002 lalr_analysis.py:229(compute_includes_lookback)
        1    0.000    0.000    0.002    0.002 lalr_analysis.py:258(compute_lookaheads)
     1010    0.000    0.000    0.001    0.000 earley_common.py:25(advance)
    19256    0.001    0.000    0.001    0.000 {method 'group' of 're.Match' objects}
      456    0.000    0.000    0.001    0.000 load_grammar.py:631(expansions)
     4542    0.001    0.000    0.001    0.000 grammar_analysis.py:45(__hash__)
      836    0.000    0.000    0.001    0.000 earley_forest.py:84(children)
      798    0.001    0.000    0.001    0.000 load_grammar.py:536(_rfind)
      798    0.001    0.000    0.001    0.000 {built-in method builtins.compile}
        1    0.000    0.000    0.001    0.001 lexer.py:568(_build_scanner)
     6833    0.001    0.000    0.001    0.000 sre_parse.py:165(__getitem__)
        1    0.000    0.000    0.001    0.001 lexer.py:357(__init__)
       45    0.000    0.000    0.001    0.000 sre_compile.py:622(_code)
     1010    0.000    0.000    0.001    0.000 earley_forest.py:63(add_family)
        1    0.000    0.000    0.001    0.001 lexer.py:368(_build_mres)
     3512    0.001    0.000    0.001    0.000 utils.py:324(__init__)
     3969    0.001    0.000    0.001    0.000 grammar_analysis.py:17(__init__)
     4308    0.001    0.000    0.001    0.000 {built-in method fromkeys}
      418    0.000    0.000    0.001    0.000 earley_forest.py:413(visit_symbol_node_in)
       38    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:1070(get_data)
      456    0.001    0.000    0.001    0.000 earley_forest.py:594(transform_packed_node)
      196    0.000    0.000    0.001    0.000 utils.py:254(classify_bool)
      878    0.001    0.000    0.001    0.000 earley_forest.py:50(__init__)
1748/1596    0.000    0.000    0.001    0.000 tree.py:130(__hash__)
      196    0.000    0.000    0.001    0.000 utils.py:256(<listcomp>)
      914    0.000    0.000    0.001    0.000 grammar.py:103(__init__)
      190    0.001    0.000    0.001    0.000 load_grammar.py:450(pattern)
    16720    0.001    0.000    0.001    0.000 {built-in method builtins.setattr}
       39    0.001    0.000    0.001    0.000 parse_tree_builder.py:358(create_callback)
       38    0.001    0.000    0.001    0.000 {built-in method io.open}
      304    0.000    0.000    0.001    0.000 earley_forest.py:435(visit_symbol_node_out)
      836    0.000    0.000    0.001    0.000 {built-in method builtins.sorted}
     1900    0.000    0.000    0.001    0.000 copy.py:264(<genexpr>)
     4577    0.001    0.000    0.001    0.000 sre_parse.py:250(match)
     1199    0.000    0.000    0.001    0.000 {built-in method builtins.max}
       38    0.000    0.000    0.001    0.000 load_grammar.py:793(<setcomp>)
       38    0.001    0.000    0.001    0.000 load_grammar.py:1292(_remove_unused)
      950    0.000    0.000    0.001    0.000 grammar.py:50(renamed)
   227/45    0.000    0.000    0.001    0.000 sre_compile.py:87(_compile)
        1    0.000    0.000    0.001    0.001 lalr_analysis.py:267(compute_lalr1_states)
      748    0.001    0.000    0.001    0.000 sre_parse.py:356(_escape)
     5706    0.001    0.000    0.001    0.000 {method 'add' of 'set' objects}
        1    0.000    0.000    0.001    0.001 lalr_analysis.py:194(compute_reads_relations)
     2034    0.000    0.000    0.001    0.000 grammar.py:22(__ne__)
      456    0.000    0.000    0.001    0.000 earley_forest.py:623(visit_packed_node_in)
       30    0.000    0.000    0.001    0.000 lexer.py:107(min_width)
       38    0.001    0.000    0.001    0.000 {built-in method io.open_code}
       60    0.000    0.000    0.001    0.000 lexer.py:102(_get_width)
        2    0.000    0.000    0.001    0.000 lalr_analysis.py:106(digraph)
     2014    0.001    0.000    0.001    0.000 load_grammar.py:1030(mangle)
       90    0.000    0.000    0.001    0.000 Workbook.py:390(get_cell_value)
      562    0.000    0.000    0.001    0.000 re.py:197(search)
      332    0.000    0.000    0.001    0.000 Sheet.py:38(split_cell_ref)
      141    0.000    0.000    0.001    0.000 Sheet.py:13(get_cell)
      570    0.000    0.000    0.001    0.000 lexer.py:81(to_regexp)
       39    0.000    0.000    0.001    0.000 grammar_analysis.py:160(<dictcomp>)
      154    0.000    0.000    0.001    0.000 {method 'join' of 'str' objects}
      304    0.000    0.000    0.001    0.000 earley_forest.py:572(transform_symbol_node)
  216/161    0.000    0.000    0.001    0.000 lalr_analysis.py:123(traverse)
        1    0.000    0.000    0.001    0.001 load_grammar.py:929(<listcomp>)
     5700    0.001    0.000    0.001    0.000 {method 'count' of 'str' objects}
     3603    0.000    0.000    0.001    0.000 utils.py:333(__iter__)
     3674    0.000    0.000    0.001    0.000 sre_parse.py:173(append)
    11419    0.001    0.000    0.001    0.000 {method 'pop' of 'list' objects}
      760    0.000    0.000    0.001    0.000 load_grammar.py:798(<lambda>)
       39    0.000    0.000    0.001    0.000 grammar_analysis.py:175(<dictcomp>)
     1976    0.000    0.000    0.001    0.000 load_grammar.py:759(<genexpr>)
      562    0.000    0.000    0.001    0.000 lexer.py:125(__init__)
      494    0.000    0.000    0.001    0.000 load_grammar.py:639(<genexpr>)
     2394    0.000    0.000    0.001    0.000 load_grammar.py:537(<genexpr>)
      228    0.000    0.000    0.001    0.000 utils.py:187(dedup_list)
     7832    0.001    0.000    0.001    0.000 {built-in method builtins.next}
       28    0.000    0.000    0.001    0.000 Workbook.py:420(get_cell_ref_info)
      202    0.000    0.000    0.001    0.000 lalr_analysis.py:176(<setcomp>)
     2688    0.000    0.000    0.001    0.000 sre_parse.py:287(tell)
      456    0.000    0.000    0.001    0.000 earley_forest.py:418(visit_packed_node_in)
      185    0.000    0.000    0.001    0.000 Sheet.py:45(out_of_bounds)
     3261    0.000    0.000    0.001    0.000 sre_parse.py:161(__len__)
     1010    0.000    0.000    0.001    0.000 earley_forest.py:122(__init__)
      607    0.000    0.000    0.000    0.000 sre_parse.py:225(__init__)
      142    0.000    0.000    0.000    0.000 load_grammar.py:902(symbol_from_strcase)
     9804    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}
      115    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
       39    0.000    0.000    0.000    0.000 grammar_analysis.py:82(<setcomp>)
       38    0.000    0.000    0.000    0.000 {method 'read' of '_io.TextIOWrapper' objects}
      162    0.000    0.000    0.000    0.000 sre_parse.py:97(closegroup)
     9693    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}
     8516    0.000    0.000    0.000    0.000 visitors.py:182(__default_token__)
      902    0.000    0.000    0.000    0.000 parser_frontends.py:184(match)
      342    0.000    0.000    0.000    0.000 load_grammar.py:1054(_make_rule_tuple)
       45    0.000    0.000    0.000    0.000 sre_compile.py:560(_compile_info)
     3458    0.000    0.000    0.000    0.000 {method 'rindex' of 'str' objects}
      950    0.000    0.000    0.000    0.000 {method '__reduce_ex__' of 'object' objects}
       40    0.000    0.000    0.000    0.000 Workbook.py:142(get_cell)
     1672    0.000    0.000    0.000    0.000 load_grammar.py:1111(_check_options)
     7512    0.000    0.000    0.000    0.000 earley_common.py:31(__hash__)
     4457    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
     2614    0.000    0.000    0.000    0.000 grammar.py:42(__init__)
     2546    0.000    0.000    0.000    0.000 load_grammar.py:918(<lambda>)
     4124    0.000    0.000    0.000    0.000 {built-in method builtins.min}
     4741    0.000    0.000    0.000    0.000 grammar_analysis.py:28(next)
     4180    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
      570    0.000    0.000    0.000    0.000 re.py:269(escape)
     1672    0.000    0.000    0.000    0.000 load_grammar.py:1079(__init__)
      380    0.000    0.000    0.000    0.000 load_grammar.py:637(<lambda>)
     2173    0.000    0.000    0.000    0.000 sre_parse.py:112(__init__)
      262    0.000    0.000    0.000    0.000 grammar_analysis.py:32(advance)
      149    0.000    0.000    0.000    0.000 Workbook.py:137(is_valid_location)
      304    0.000    0.000    0.000    0.000 earley_forest.py:556(_call_rule_func)
      980    0.000    0.000    0.000    0.000 lexer.py:41(__init__)
      332    0.000    0.000    0.000    0.000 Sheet.py:31(str_to_index)
     1102    0.000    0.000    0.000    0.000 lexer.py:50(__hash__)
     1416    0.000    0.000    0.000    0.000 {built-in method builtins.any}
      234    0.000    0.000    0.000    0.000 sre_parse.py:868(_parse_flags)
       38    0.000    0.000    0.000    0.000 lark.py:188(__init__)
      158    0.000    0.000    0.000    0.000 grammar_analysis.py:60(__init__)
     5237    0.000    0.000    0.000    0.000 {built-in method builtins.iter}
      149    0.000    0.000    0.000    0.000 re.py:187(match)
      603    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)
      912    0.000    0.000    0.000    0.000 earley_forest.py:136(sort_key)
      114    0.000    0.000    0.000    0.000 parser_frontends.py:96(_make_lexer_thread)
      878    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}
       76    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}
      304    0.000    0.000    0.000    0.000 earley_forest.py:547(_collapse_ambig)
      114    0.000    0.000    0.000    0.000 earley_forest.py:438(visit_intermediate_node_out)
       38    0.000    0.000    0.000    0.000 earley.py:53(<setcomp>)
     1026    0.000    0.000    0.000    0.000 load_grammar.py:668(value)
      566    0.000    0.000    0.000    0.000 sre_parse.py:433(_uniq)
    30/10    0.000    0.000    0.000    0.000 Workbook.py:188(calculate_out_degree)
      800    0.000    0.000    0.000    0.000 {built-in method builtins.all}
       38    0.000    0.000    0.000    0.000 load_grammar.py:443(__init__)
      950    0.000    0.000    0.000    0.000 copyreg.py:100(__newobj__)
      607    0.000    0.000    0.000    0.000 sre_parse.py:928(fix_flags)
      646    0.000    0.000    0.000    0.000 load_grammar.py:911(nonterminal)
     4750    0.000    0.000    0.000    0.000 copy.py:182(_deepcopy_atomic)
     1938    0.000    0.000    0.000    0.000 lark.py:217(__getattr__)
       30    0.000    0.000    0.000    0.000 _collections_abc.py:649(__or__)
     1379    0.000    0.000    0.000    0.000 grammar_analysis.py:36(is_satisfied)
     4926    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}
     1124    0.000    0.000    0.000    0.000 parse_tree_builder.py:158(_should_expand)
       38    0.000    0.000    0.000    0.000 {method 'read' of '_io.BufferedReader' objects}
      114    0.000    0.000    0.000    0.000 posixpath.py:71(join)
      500    0.000    0.000    0.000    0.000 lexer.py:98(to_regexp)
       28    0.000    0.000    0.000    0.000 Workbook.py:378(detect_cycle)
     4477    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
     1070    0.000    0.000    0.000    0.000 lexer.py:70(_get_flags)
     4115    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
       52    0.000    0.000    0.000    0.000 sre_compile.py:292(_optimize_charset)
       38    0.000    0.000    0.000    0.000 earley.py:52(<setcomp>)
       76    0.000    0.000    0.000    0.000 earley.py:285(<genexpr>)
     1634    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}
      456    0.000    0.000    0.000    0.000 earley_forest.py:146(children)
      342    0.000    0.000    0.000    0.000 earley.py:58(<listcomp>)
      582    0.000    0.000    0.000    0.000 sre_parse.py:169(__setitem__)
       30    0.000    0.000    0.000    0.000 _collections_abc.py:626(_from_iterable)
       38    0.000    0.000    0.000    0.000 load_grammar.py:806(<setcomp>)
       38    0.000    0.000    0.000    0.000 load_grammar.py:446(<dictcomp>)
      722    0.000    0.000    0.000    0.000 load_grammar.py:621(expansion)
    98/28    0.000    0.000    0.000    0.000 Workbook.py:360(dfs)
     3824    0.000    0.000    0.000    0.000 {method 'pop' of 'collections.deque' objects}
      418    0.000    0.000    0.000    0.000 earley_forest.py:69(load_paths)
      798    0.000    0.000    0.000    0.000 ast.py:84(_convert)
      162    0.000    0.000    0.000    0.000 sre_parse.py:85(opengroup)
     1790    0.000    0.000    0.000    0.000 grammar.py:15(__init__)
       39    0.000    0.000    0.000    0.000 grammar_analysis.py:145(<dictcomp>)
     2166    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}
       38    0.000    0.000    0.000    0.000 load_grammar.py:1419(sha256_digest)
      570    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}
       76    0.000    0.000    0.000    0.000 load_grammar.py:1285(<dictcomp>)
       76    0.000    0.000    0.000    0.000 lexer.py:439(from_text)
      836    0.000    0.000    0.000    0.000 utils.py:342(__len__)
      607    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)
      418    0.000    0.000    0.000    0.000 earley_forest.py:490(__init__)
      562    0.000    0.000    0.000    0.000 utils.py:144(<listcomp>)
      603    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}
      190    0.000    0.000    0.000    0.000 load_grammar.py:346(expr)
        1    0.000    0.000    0.000    0.000 lalr_analysis.py:81(from_ParseTable)
      451    0.000    0.000    0.000    0.000 typing.py:306(inner)
     1710    0.000    0.000    0.000    0.000 typing.py:1737(cast)
      114    0.000    0.000    0.000    0.000 earley_forest.py:582(transform_intermediate_node)
       38    0.000    0.000    0.000    0.000 parser_frontends.py:127(_get_lexer_callbacks)
      134    0.000    0.000    0.000    0.000 grammar_analysis.py:40(__eq__)
        2    0.000    0.000    0.000    0.000 transformer.py:42(cell)
       38    0.000    0.000    0.000    0.000 load_grammar.py:642(expr)
      349    0.000    0.000    0.000    0.000 lalr_analysis.py:172(<lambda>)
        2    0.000    0.000    0.000    0.000 transformer.py:13(sheet_name_needs_quotes)
       39    0.000    0.000    0.000    0.000 common.py:42(__init__)
     1501    0.000    0.000    0.000    0.000 parse_tree_builder.py:182(<genexpr>)
        2    0.000    0.000    0.000    0.000 re.py:192(fullmatch)
      950    0.000    0.000    0.000    0.000 visitors.py:108(__init__)
     1362    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
       28    0.000    0.000    0.000    0.000 visitors.py:419(visit)
      562    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}
     1331    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      458    0.000    0.000    0.000    0.000 grammar.py:69(__init__)
       38    0.000    0.000    0.000    0.000 earley_forest.py:514(__init__)
     1733    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}
     1026    0.000    0.000    0.000    0.000 load_grammar.py:572(<genexpr>)
     1026    0.000    0.000    0.000    0.000 load_grammar.py:1232(<genexpr>)
       76    0.000    0.000    0.000    0.000 lexer.py:252(new_borrow_pos)
       39    0.000    0.000    0.000    0.000 grammar_analysis.py:166(<dictcomp>)
      152    0.000    0.000    0.000    0.000 earley_forest.py:423(visit_token_node)
       28    0.000    0.000    0.000    0.000 visitors.py:425(_visit_tree)
       76    0.000    0.000    0.000    0.000 lexer.py:416(__init__)
      912    0.000    0.000    0.000    0.000 earley_forest.py:132(is_empty)
      112    0.000    0.000    0.000    0.000 DependencyGraph.py:16(outgoing_get)
       45    0.000    0.000    0.000    0.000 enum.py:986(__and__)
      120    0.000    0.000    0.000    0.000 lalr_analysis.py:88(<dictcomp>)
      180    0.000    0.000    0.000    0.000 earley_forest.py:184(__init__)
      874    0.000    0.000    0.000    0.000 earley_forest.py:539(_check_cycle)
      120    0.000    0.000    0.000    0.000 lalr_analysis.py:271(<dictcomp>)
      456    0.000    0.000    0.000    0.000 earley_forest.py:149(<listcomp>)
       38    0.000    0.000    0.000    0.000 posixpath.py:150(dirname)
     1212    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
      114    0.000    0.000    0.000    0.000 lark.py:223(__setattr__)
       10    0.000    0.000    0.000    0.000 Sheet.py:73(resize)
       39    0.000    0.000    0.000    0.000 grammar_analysis.py:163(<dictcomp>)
      532    0.000    0.000    0.000    0.000 load_grammar.py:809(<lambda>)
      414    0.000    0.000    0.000    0.000 sre_parse.py:82(groups)
      380    0.000    0.000    0.000    0.000 lexer.py:88(max_width)
       38    0.000    0.000    0.000    0.000 parser_frontends.py:116(_validate_frontend_args)
        4    0.000    0.000    0.000    0.000 Workbook.py:335(get_cell_contents)
      875    0.000    0.000    0.000    0.000 grammar_analysis.py:149(<lambda>)
      304    0.000    0.000    0.000    0.000 earley_forest.py:562(_call_ambig_func)
     1010    0.000    0.000    0.000    0.000 earley_forest.py:160(__hash__)
       38    0.000    0.000    0.000    0.000 load_grammar.py:1159(_ignore)
      380    0.000    0.000    0.000    0.000 lexer.py:84(min_width)
       30    0.000    0.000    0.000    0.000 sre_parse.py:268(getuntil)
       38    0.000    0.000    0.000    0.000 load_grammar.py:1180(_unpack_import)
       38    0.000    0.000    0.000    0.000 {built-in method _hashlib.openssl_sha256}
      114    0.000    0.000    0.000    0.000 load_grammar.py:613(_make_joined_pattern)
      760    0.000    0.000    0.000    0.000 load_grammar.py:431(expansion)
      438    0.000    0.000    0.000    0.000 utils.py:339(__bool__)
      120    0.000    0.000    0.000    0.000 lalr_analysis.py:297(<dictcomp>)
       76    0.000    0.000    0.000    0.000 lalr_parser_state.py:22(__init__)
       38    0.000    0.000    0.000    0.000 codecs.py:319(decode)
      608    0.000    0.000    0.000    0.000 load_grammar.py:617(pattern)
      114    0.000    0.000    0.000    0.000 parser_frontends.py:86(_verify_start)
      262    0.000    0.000    0.000    0.000 lalr_analysis.py:174(<lambda>)
      836    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}
      875    0.000    0.000    0.000    0.000 grammar_analysis.py:172(<lambda>)
      608    0.000    0.000    0.000    0.000 load_grammar.py:663(value)
       76    0.000    0.000    0.000    0.000 visitors.py:167(__mul__)
       36    0.000    0.000    0.000    0.000 visitor.py:10(cell)
      114    0.000    0.000    0.000    0.000 load_grammar.py:640(<setcomp>)
      469    0.000    0.000    0.000    0.000 parse_tree_builder.py:17(__init__)
       61    0.000    0.000    0.000    0.000 sre_compile.py:447(_simple)
       90    0.000    0.000    0.000    0.000 enum.py:359(__call__)
       38    0.000    0.000    0.000    0.000 load_grammar.py:1303(<dictcomp>)
       38    0.000    0.000    0.000    0.000 earley_forest.py:381(__init__)
       38    0.000    0.000    0.000    0.000 codecs.py:309(__init__)
       12    0.000    0.000    0.000    0.000 sre_compile.py:435(_mk_bitmap)
       76    0.000    0.000    0.000    0.000 load_grammar.py:1094(__init__)
       52    0.000    0.000    0.000    0.000 sre_compile.py:265(_compile_charset)
    46/45    0.000    0.000    0.000    0.000 sre_compile.py:485(_get_literal_prefix)
       38    0.000    0.000    0.000    0.000 load_grammar.py:516(__init__)
      152    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)
        1    0.000    0.000    0.000    0.000 load_grammar.py:925(<listcomp>)
       38    0.000    0.000    0.000    0.000 lark.py:413(<dictcomp>)
       28    0.000    0.000    0.000    0.000 interpreter.py:149(cell)
       62    0.000    0.000    0.000    0.000 DependencyGraph.py:24(ingoing_get)
       76    0.000    0.000    0.000    0.000 visitors.py:267(__mul__)
       38    0.000    0.000    0.000    0.000 util.py:73(find_spec)
        4    0.000    0.000    0.000    0.000 Sheet.py:81(get_cell_contents)
      189    0.000    0.000    0.000    0.000 parse_tree_builder.py:187(<listcomp>)
       38    0.000    0.000    0.000    0.000 load_grammar.py:743(<setcomp>)
       76    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)
      266    0.000    0.000    0.000    0.000 exceptions.py:19(assert_config)
       39    0.000    0.000    0.000    0.000 common.py:45(<dictcomp>)
        2    0.000    0.000    0.000    0.000 typing.py:1138(__getitem__)
      664    0.000    0.000    0.000    0.000 {method 'isalpha' of 'str' objects}
      289    0.000    0.000    0.000    0.000 _collections_abc.py:652(<genexpr>)
      152    0.000    0.000    0.000    0.000 load_grammar.py:434(alias)
       38    0.000    0.000    0.000    0.000 load_grammar.py:228(__init__)
       38    0.000    0.000    0.000    0.000 load_grammar.py:797(<setcomp>)
       38    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}
       10    0.000    0.000    0.000    0.000 Sheet.py:51(resize_sheet)
      189    0.000    0.000    0.000    0.000 parse_tree_builder.py:141(__init__)
       76    0.000    0.000    0.000    0.000 lalr_parser_state.py:40(__init__)
        1    0.000    0.000    0.000    0.000 load_grammar.py:927(<listcomp>)
       66    0.000    0.000    0.000    0.000 earley_forest.py:155(__eq__)
      342    0.000    0.000    0.000    0.000 load_grammar.py:1072(<listcomp>)
       76    0.000    0.000    0.000    0.000 lexer.py:279(__init__)
      342    0.000    0.000    0.000    0.000 load_grammar.py:428(expansions)
       38    0.000    0.000    0.000    0.000 load_grammar.py:445(<setcomp>)
        2    0.000    0.000    0.000    0.000 typing.py:1147(copy_with)
      152    0.000    0.000    0.000    0.000 load_grammar.py:411(alias)
       38    0.000    0.000    0.000    0.000 xearley.py:36(<listcomp>)
       38    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}
      152    0.000    0.000    0.000    0.000 visitors.py:259(__init__)
        2    0.000    0.000    0.000    0.000 typing.py:1016(__init__)
       90    0.000    0.000    0.000    0.000 sre_compile.py:619(isstring)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.print}
      122    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
       19    0.000    0.000    0.000    0.000 sre_compile.py:516(_get_charset_prefix)
       76    0.000    0.000    0.000    0.000 lexer.py:443(lex)
       12    0.000    0.000    0.000    0.000 sre_compile.py:437(<listcomp>)
       39    0.000    0.000    0.000    0.000 parse_tree_builder.py:83(make_propagate_positions)
        1    0.000    0.000    0.000    0.000 __init__.py:71(search_function)
       39    0.000    0.000    0.000    0.000 common.py:80(__init__)
      194    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}
      120    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}
       90    0.000    0.000    0.000    0.000 enum.py:678(__new__)
        1    0.000    0.000    0.000    0.000 lexer.py:334(_create_unless)
       38    0.000    0.000    0.000    0.000 <string>:1(<lambda>)
       76    0.000    0.000    0.000    0.000 lexer.py:435(__init__)
       36    0.000    0.000    0.000    0.000 visitor.py:6(__init__)
        7    0.000    0.000    0.000    0.000 lexer.py:556(<genexpr>)
      180    0.000    0.000    0.000    0.000 earley_forest.py:198(__hash__)
        6    0.000    0.000    0.000    0.000 case.py:840(assertEqual)
       26    0.000    0.000    0.000    0.000 sre_compile.py:456(_generate_overlap_table)
       31    0.000    0.000    0.000    0.000 lexer.py:375(<genexpr>)
       38    0.000    0.000    0.000    0.000 {method 'issuperset' of 'set' objects}
       30    0.000    0.000    0.000    0.000 lexer.py:559(<lambda>)
       45    0.000    0.000    0.000    0.000 {built-in method _sre.compile}
      152    0.000    0.000    0.000    0.000 {built-in method posix.fspath}
        2    0.000    0.000    0.000    0.000 Workbook.py:52(new_sheet)
       38    0.000    0.000    0.000    0.000 codecs.py:260(__init__)
      8/6    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)
       56    0.000    0.000    0.000    0.000 {method 'index' of 'str' objects}
      122    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}
       76    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)
       16    0.000    0.000    0.000    0.000 typing.py:986(__setattr__)
       38    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}
        8    0.000    0.000    0.000    0.000 DependencyGraph.py:58(ingoing_add)
       38    0.000    0.000    0.000    0.000 load_grammar.py:685(__init__)
      8/6    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}
       38    0.000    0.000    0.000    0.000 load_grammar.py:1029(_get_mangle)
      150    0.000    0.000    0.000    0.000 {method 'keys' of 'collections.OrderedDict' objects}
       38    0.000    0.000    0.000    0.000 load_grammar.py:1293(rule_dependencies)
      152    0.000    0.000    0.000    0.000 earley_forest.py:409(transform_token_node)
      180    0.000    0.000    0.000    0.000 {method 'end' of 're.Match' objects}
        1    0.000    0.000    0.000    0.000 lalr_analysis.py:308(<dictcomp>)
       51    0.000    0.000    0.000    0.000 sre_compile.py:81(_combine_flags)
        2    0.000    0.000    0.000    0.000 typing.py:947(__init__)
       38    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
       38    0.000    0.000    0.000    0.000 earley_forest.py:223(__init__)
       65    0.000    0.000    0.000    0.000 sre_compile.py:477(_get_iscased)
        1    0.000    0.000    0.000    0.000 Workbook.py:654(move_sheet)
        4    0.000    0.000    0.000    0.000 case.py:1053(assertTupleEqual)
       10    0.000    0.000    0.000    0.000 DependencyGraph.py:35(outgoing_set)
      114    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
       76    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)
        1    0.000    0.000    0.000    0.000 __init__.py:43(normalize_encoding)
       28    0.000    0.000    0.000    0.000 interpreter.py:9(__init__)
       38    0.000    0.000    0.000    0.000 load_grammar.py:498(__init__)
      142    0.000    0.000    0.000    0.000 {method 'isupper' of 'str' objects}
        4    0.000    0.000    0.000    0.000 DependencyGraph.py:81(ingoing_remove)
       38    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
       42    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}
        1    0.000    0.000    0.000    0.000 lalr_analysis.py:84(<dictcomp>)
        4    0.000    0.000    0.000    0.000 typing.py:1143(<genexpr>)
       77    0.000    0.000    0.000    0.000 {built-in method builtins.callable}
       30    0.000    0.000    0.000    0.000 lexer.py:111(max_width)
        5    0.000    0.000    0.000    0.000 Sheet.py:19(to_sheet_coords)
       16    0.000    0.000    0.000    0.000 typing.py:935(_is_dunder)
        2    0.000    0.000    0.000    0.000 Cell.py:17(is_number)
       40    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
        2    0.000    0.000    0.000    0.000 contextlib.py:139(__exit__)
        1    0.000    0.000    0.000    0.000 utf_8.py:33(getregentry)
        4    0.000    0.000    0.000    0.000 case.py:936(assertSequenceEqual)
       30    0.000    0.000    0.000    0.000 lexer.py:394(_regexp_has_newline)
        1    0.000    0.000    0.000    0.000 copyreg.py:109(_slotnames)
       31    0.000    0.000    0.000    0.000 lexer.py:528(<genexpr>)
        2    0.000    0.000    0.000    0.000 typing.py:146(_type_check)
        6    0.000    0.000    0.000    0.000 case.py:807(_getAssertEqualityFunc)
       68    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}
        2    0.000    0.000    0.000    0.000 contextlib.py:279(helper)
        5    0.000    0.000    0.000    0.000 Cell.py:11(__init__)
       12    0.000    0.000    0.000    0.000 sre_parse.py:296(_class_escape)
        1    0.000    0.000    0.000    0.000 codecs.py:94(__new__)
        2    0.000    0.000    0.000    0.000 contextlib.py:102(__init__)
        2    0.000    0.000    0.000    0.000 typing.py:953(__call__)
       12    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}
        4    0.000    0.000    0.000    0.000 case.py:54(testPartExecutor)
        1    0.000    0.000    0.000    0.000 Workbook.py:26(__init__)
       30    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}
       10    0.000    0.000    0.000    0.000 Workbook.py:160(<dictcomp>)
        1    0.000    0.000    0.000    0.000 lexer.py:547(<setcomp>)
        2    0.000    0.000    0.000    0.000 _collections_abc.py:262(__subclasshook__)
        3    0.000    0.000    0.000    0.000 CellError.py:48(__init__)
        2    0.000    0.000    0.000    0.000 Workbook.py:35(list_sheets)
       41    0.000    0.000    0.000    0.000 {built-in method _sre.unicode_iscased}
       30    0.000    0.000    0.000    0.000 lexer.py:335(<lambda>)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.__import__}
        1    0.000    0.000    0.000    0.000 case.py:551(_callTearDown)
        1    0.000    0.000    0.000    0.000 Workbook.py:548(update_cell_sn)
        2    0.000    0.000    0.000    0.000 typing.py:206(_collect_type_vars)
        2    0.000    0.000    0.000    0.000 contextlib.py:130(__enter__)
        1    0.000    0.000    0.000    0.000 test_performance.py:21(tearDown)
        1    0.000    0.000    0.000    0.000 lexer.py:364(<setcomp>)
        2    0.000    0.000    0.000    0.000 {built-in method math.isnan}
        2    0.000    0.000    0.000    0.000 lalr_analysis.py:39(__init__)
        1    0.000    0.000    0.000    0.000 lexer.py:352(<listcomp>)
       27    0.000    0.000    0.000    0.000 {built-in method _sre.unicode_tolower}
        2    0.000    0.000    0.000    0.000 _collections_abc.py:78(_check_methods)
        2    0.000    0.000    0.000    0.000 {method 'fullmatch' of 're.Pattern' objects}
       10    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}
        2    0.000    0.000    0.000    0.000 DependencyGraph.py:9(add_sheet)
        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}
        2    0.000    0.000    0.000    0.000 Sheet.py:7(__init__)
        2    0.000    0.000    0.000    0.000 typing.py:137(_type_convert)
        2    0.000    0.000    0.000    0.000 case.py:833(_baseAssertEqual)
        2    0.000    0.000    0.000    0.000 typing.py:223(_check_generic)
        4    0.000    0.000    0.000    0.000 typing.py:1022(<genexpr>)
        1    0.000    0.000    0.000    0.000 Workbook.py:32(num_sheets)
        2    0.000    0.000    0.000    0.000 Workbook.py:65(<listcomp>)
        1    0.000    0.000    0.000    0.000 {method 'pop' of 'collections.OrderedDict' objects}
        1    0.000    0.000    0.000    0.000 transformer.py:9(__init__)
       12    0.000    0.000    0.000    0.000 {method 'isalnum' of 'str' objects}
        1    0.000    0.000    0.000    0.000 lalr_parser.py:78(__init__)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}
        5    0.000    0.000    0.000    0.000 {built-in method builtins.chr}
        2    0.000    0.000    0.000    0.000 Cell.py:30(strip_trailing_zeros)
        4    0.000    0.000    0.000    0.000 {method 'isascii' of 'str' objects}
        2    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 DependencyGraph.py:5(__init__)
        3    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
        1    0.000    0.000    0.000    0.000 lalr_analysis.py:319(<dictcomp>)
        2    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}
        1    0.000    0.000    0.000    0.000 lalr_analysis.py:93(<dictcomp>)
        1    0.000    0.000    0.000    0.000 lalr_analysis.py:94(<dictcomp>)


